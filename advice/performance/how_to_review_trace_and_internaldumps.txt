1. trsum.awk trcxxx > output.trc
2. Search VFS and check output, check which part was costing time:
############This one is okay###########
Elapsed trace time:                                   43.267410000 seconds
Elapsed trace time from first VFS call to last:       43.183933999
Time idle between VFS calls:                           1.647694000 seconds

Operations stats:             total time(s)  count    avg-usecs        wait-time(s)    avg-usecs
  read_inode2                0.045623000      2592       17.601
  rdwr                      24.921507000    259384       96.080
  pagein                     2.181476000     15501      140.731
  revalidate                 0.000156000        20        7.800
  write_inode                0.000115000        21        5.476
  create                     0.001131000         1     1131.000
  link                       0.000076000         1       76.000
  open                       0.099441000       517      192.342
  unlink                     0.000361000         2      180.500
  setattr                    0.000014000        15        0.933
  lookup                     5.925464000      3034     1953.020
  delete_inode               0.055062000      2531       21.755
  release                    0.008361000       518       16.141
  write_super                0.000197000         7       28.143
  mkdir                      0.002841000         6      473.500
  getxattr                   0.000050000         4       12.500
  readdir                    0.001249000        27       46.259
  mmap                       0.016709000       651       25.667
  llseek                     0.000007000        24        0.292
  statfs                     0.001252000       151        8.291
Ops    285007 Secs      41.536239999  Ops/Sec     6861.647
#######################

3. Ex, rdwr costing time, seach at top of "rdwr", and find in original trace file by "timestamp" and "process id":
    "2219"       "0.464876000" WRITE: gnP 0xFFFF8818078A9E90 inode 4302101 snap 0 oiP 0xFFFFC90037308AF8 offset 0x4971CC len 162 blkSize 262144 opt 0
    2219       0.464889000 rdwr                       17.000 us
    2219       0.464897000 rdwr                              ext        8.000 us
[Original trace file]
   0.464876   2219 TRACE_VNOP: WRITE: gnP 0xFFFF8818078A9E90 inode 4302101 snap 0 oiP 0xFFFFC90037308AF8 offset 0x4971CC len 162 blkSize 262144 opt 0
   0.464876   2219 TRACE_FS: updateAccessHistoryM: FETCH oiP 0xFFFFC90037308AF8 newOffset 0x4971CC len 162 blockNum 18 oldPattern seq newPattern seq pa

4. check dump vfsstats in dumpall file:
===== dump vfsstats =====
Current time 2019-06-13_16:17:46+0800
[statistics last reset at Wed Jun 12 22:13:12 2019]
vfs statistics currently enabled
started at: Wed Jun 12 22:13:10.756 2019
  duration: 65075.847 sec

 name                      calls  time per call     total time
 -------------------- ---------- -------------- --------------
 access                  1562375       0.000005       7.726629
 close                    350480       0.000005       1.822685
 getattr                 1383699       0.000032      43.903121
 lookup                   989833       0.000746     738.753286
 open                     350498       0.000058      20.226663
 read                     561282       0.001412     792.333111
 readdir                   49179       0.000245      12.033966
 getxattr                 133642       0.000004       0.571668
 statfs                        1       0.000010       0.000010

Õâ¸öÊÇnsd server node£º
===== dump vfsstats =====
Current time 2019-06-13_16:16:59+0800
[statistics last reset at Wed Jun 12 22:12:24 2019]
vfs statistics currently enabled
started at: Wed Jun 12 22:12:23.141 2019
  duration: 65076.346 sec

 name                      calls  time per call     total time
 -------------------- ---------- -------------- --------------
 getattr                    6716       0.000063       0.422581
 readlink                   3400       0.000002       0.006121
 statfs                      108       0.000007       0.000785
 startIO                 8874517       0.015849  140649.775257


   
5. Besides trace file, you can also find something from internaldumps file:
===== dump fs =====
  OpenFile counts: total created 4254 (in use 4000, free 254 q 0)
    cached 4000, currently open 474+3, cache limit 4000 (min 10, max 4000), eff limit 4000
  OpenInstance counts: in use 1270 free 778 total 2048 using 1344K memory
  NFS instance limit: 4000
  fileCacheMemUsed 27776000, openFileMemUsed 3291456, limit 129010707520, eff limit 129010707520
    stats: ins 425584 rem 421584 creat 41970 destr 37716 free 236054 reuse 235800
           steals 220421 (clean 216343, dirty 4078)

Explain:
1) maxFilesToCache --> cache limit 4000
2) total 2048 --> current using, if < 4000, then maxFilesToCache is okay, or need increase maxFilesToCache value.
3) steals 220421 (clean 216343, dirty 4078) --> when exceed maxFilesToCache, need steal more to gain space for new
	if this value too large, also need increase maxFilesToCache value.
	
===== dump mb =====
Worker1Threads: max 48 current limit 48 in use 0 waiting 0

Explain:
1) Worker1Threads --> Worker1Threads: max 48
2) in use 0 waiting 0 --> If too large need to increase Worker1Threads


===== dump waiters =====
1) Check if any Locker threads, if yes review carefully on each process. Find lock on what.
2) Check if any nsd complete waiting threads, find any disk problem.


===== dump rpc/dump tscomm =====
network related.


===== dump iohist =====

I/O history:

 I/O start time RW    Buf type disk:sectorNum     nSec  time ms      tag1      tag2           Disk UID typ      NSD node context   thread
--------------- -- ----------- ----------------- -----  ------- --------- --------- ------------------ --- --------------- --------- ----------
17:44:36.327163  W        data    3:1435806208     512    1.624   5497036     12541  0A057F1A:5BD546A2 cli   192.168.12.29 Cleaner   CleanBufferThread
17:44:36.327553  W        data    2:1435779072     512    1.551   5497036     12480  0A057F1A:5BD546A0 cli   192.168.12.24 Cleaner   CleanBufferThread
17:44:36.327723  W        data    1:1435747840     512    1.959   5497036     12227  0A057F1A:5BD546A4 cli   192.168.12.29 Cleaner   CleanBufferThread

Explanation:
1) No need to use iohist.awk, check "time ms", if local write large than 200ms, consider a problem, if remote access, add the value.
2) Search "0A057F1A" In "dump nsd"
===== dump nsd =====

NSD configuration:

  Disk name   NsdId              Cl  St F Local dev  Dev type Dev Usage       Servers                          Addr/rcfg
  ----------  -----------------  --  -- - ---------- -------- --------------- -------------------------------- ----
  nsd1        0A057F1F:5BD545D9   0  N  1             generic dataAndMetadata <c0n2> <c0n0> 0x2B07041FF000/0x0
  nsd2        0A057F1A:5BD54633   0  N  1             generic dataAndMetadata <c0n0> <c0n2> 0x2B07041FF120/0x0
  nsd3        0A057F1F:5BD545DC   0  N  1             generic dataAndMetadata <c0n2> <c0n0> 0x2B07041FF6B0/0x0

then find "<c0n0> <c0n2>" from dump cfgmgr:
===== dump cfgmgr =====
node     node                primary          admin  OS --status---   join fail  SGs cnfs   rcksum   wcksum other ip addrs,
  no  address host name      ip address        func     tr p    rpc  seqNo  cnt mngd  grp mismatch mismatch last failure
---- -------- -------------- -------------- ------- --- ----------- ------ ---- ---- ---- -------- -------- -------------------
   2   "<c0n0>" tbpnode1       192.168.12.24  qQm--l-- Lnx -- J     up      3    0   0     0        0        0
   3   <c0n1> tbpnode2       192.168.12.25  qQ---l-- Lnx -- J     up      3    0   0     0        0        0
   4   <c0n3> tbpnode3       192.168.12.26  -----l-- Lnx -- J     up      3    0   0     0        0        0
   5   <c0n4> tbpnode4       192.168.12.27  -----l-- Lnx -- J     up      4    0   0     0        0        0
   1   "<c0n2>" manager1       192.168.12.29  q-m--l-- Lnx -- J     up      3    0   0     0        0        0

my address is <c0n3>, so this is a remote write.










