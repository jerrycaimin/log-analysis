Bring up:
--check ces status
mmlscluster --ces
--check node status
mmhealth node show -v
--check ces service
mmces service list
--show nfs export
mmnfs export list



[Data collection for NFS Ganesha hang or performance issue]
https://ganltc.github.io/data-collection-for-nfs-ganesha-hang-or-performance-issue.html 

[Enable ganesha trace]
mmnfs configuration change LOG_LEVEL=FULL_DEBUG
restore to default level
mmnfs configuration change LOG_LEVEL=EVENT

[How to verify the NLM port]
-----------> use rpcinfo to get lockmgr(ganesha program) rpc register info
[root@vm2 ~]# rpcinfo -p | grep lockmgr
    100021    4   udp  51880  nlockmgr
    100021    4   tcp  44216  nlockmgr
-----------> it's owned by ganesha, no problem
[root@vm2 ~]# netstat -nlp | grep tcp | grep 44216
tcp6       0      0 :::44216                :::*                    LISTEN      7789/ganesha.nfsd
-----------> but once mounted:   
[root@vm2 ~]# mount -overs=3 192.168.122.31:/nfs1 /mnt
[root@vm2 ~]# rpcinfo -p | grep lockmgr
    100021    1   udp  54303  nlockmgr
    100021    3   udp  54303  nlockmgr
    100021    4   udp  54303  nlockmgr
    100021    1   tcp  41011  nlockmgr
    100021    3   tcp  41011  nlockmgr
    100021    4   tcp  41011  nlockmgr
-----------> the lockmgr is gone, mistakenly show "-"
[root@vm2 ~]# netstat -nlp | grep tcp | grep 41011
tcp        0      0 0.0.0.0:41011           0.0.0.0:*               LISTEN      -   

Sachin also said the process owning the NLM port at failure time was displayed as DASH "-" with netstat command. 
This is another indication that this issue is really someone (or some script) mounting an NFS export on the protocol node. 
Also, ganesha only registers for version 4 but the linux kernel registers for version 1,3 and 4. 
See all the output here and a way to recreate this issue. 
"tcpdump" output also showed exactly the same signature with my recreate on my laptop as well.  
From rtc: https://jazz07.rchland.ibm.com:21443/jazz/web/projects/GPFS#action=com.ibm.team.workitem.viewWorkItem&id=176349
From pmr: https://w3-03.ibm.com/systems/techlink/psdb/global/viewRecord.do?category=PMR&uid=30083000858-20171123
[Basic description on NFS]
http://blog.51cto.com/atong/1343950

[Take ganesha coredumps]
https://ganltc.github.io/setup-to-take-ganesha-coredumps.html

[update rpm]
https://ganltc.github.io/nfs-ganesha-upgrade-instructions.html


[Set NOFILE]
>> maxFilesToCache 1000000
>> NOFILE="80000"

NOFILE should be 80% of MFTC, after reboot it set automatically.
So they must have set MTFC as 100K first and then restarted GPFS. Ganesha's NOFILE would be 80K. 
They need restart GPFS to take the new maxFilesToCache value to compute new NOFILE.

[rpc.statd permission issue "/var/lib/nfs/statd/sm/dev4: Permission denied" of /var/log/message]
https://gpfs.almaden.ibm.com/w/index.php?title=Ganesha/Problem_Determination&section=7#clients_not_monitored

[export folder for ganesha or default nfs]
If you are using CES NFS -
1. Create a directory path (For example - /gpfs/fshome/fset001) and export this path.
2. Run the command mmnfs export add /ibm/gpfs0/export1 -c "<client Nodes IP/ range>(Access_Type=RO,Squash=root_squash". For more information about the command, see mmnfs in IBM Spectrum Scale: Command and Programming Reference.
If you are using default NFS, enter the following in /etc/export:
          /gpfs/fshome/fset001 node2(rw,no_root_squash,no_subtree_check,fsid=101)
          node4:/gpfs # exportfs -rva
          node4:/gpfs # exportfs
          /gpfs/fshome/fset001

          systemctl restart nfs-server

[Add export]
mmnfs export add /gpfs1/independentwritercache --client "*(Access_Type=RW,Squash=no_root_squash,SecType=sys)"

[remove forcely]
mmnfs export remove /gpfs1/independentwritercache --force

[change ces loglevel,default=0]
mmchconfig cesLoglevel=1 -i

[upgrade ganesha issue]
https://www.ibm.com/support/knowledgecenter/en/STXKQY_5.0.0/com.ibm.spectrum.scale.v5r00.doc/bl1ins_updatingnfs.htm


[grace mode in nfsv4]


    The purpose of the grace period is to give the clients enough time to notice that the server has rebooted,
    and to reclaim their existing locks without danger of having somebody else steal the lock from them. This is
    definitely a strongly recommended feature to prevent any data corruption in your mailbox/database/logfile/...
    that relies on those locks.

    NFSv4 RFC says:

    During the grace period, the server must reject READ and WRITE operations and non-reclaim locking requests
    (i.e., other LOCK and OPEN operations) with an error of NFS4ERR_GRACE.

    To decrease grace period, follow the steps below depending on the type of environment.








