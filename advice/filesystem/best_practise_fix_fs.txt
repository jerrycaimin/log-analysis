###################
In /var/log/messages there are fsstruct errors indicating metadata corruption for 61 inodes.
$ fsstructlx.awk  */var/log/messages | grep lookup | cut -f 2 -d '(' | cut -f 1 -d ')' | sort | uniq | wc -l
61    
 
I recommend that you unmount the filesystem on all nodes and run an offline mmfsck.  

# script 
# mmfsck gpfsFS1  -v -n | tee mmfsck_gpfsFS1_n.out
# exit 

Send in the typescript file for us to evaluate.  
You can also mount the filesystem after the mmfsck -n completes in service mode:
mmmount gpfsFS1 -o rs 
and you can run a tsfindinode giving it a file containing the list of bad inodes (see above). 
This will allow you to identify the bad inodes.   
Call the support center and have them pageout the oncall to evaluate the mmfsck output,  then you can run the mmfsck -y.

# script
# mmfsck gpfsFS1 -v -y | tee mmfsck_gpfsFS1_y.out
# exit

Send in the new typescript file for us to evaluate it.
###################

1. Check fs with fsstructlx.awk on /var/log/message if any "errorcode=lookup", by this cmd:
$ fsstructlx.awk  */var/log/messages | grep lookup 

2. If fs corrupt identified, try to unmount all the fs:
# mmumount /gpfsFS1 -a
# mmlsmount all -L

3. run the mmfsck gpfsFS1 -v -n to check the output(not to fix), Policy: 
>>>>>>>>>>>If no inode in reserved problem, can run mmfsck -y, else involve dev to check. 
Analysis gpfsFS1 -v -n report, sample:
#######################
There are total 182 bad entries from the mmfsck -n output, include the duplicated address, bad indirect block and bad directory enties:
InodeProblemList: 182 entries
iNum           snapId     status keep delete noScan new error
-------------- ---------- ------ ---- ------ ------ --- ------------------
       125402          0      1    0      0      0   0 0x00000008 AddrDuplicate
       123556          0      1    0      0      0   0 0x00001408 AddrDuplicate FullBlocksBad SubblocksBad
       123682          0      1    0      0      0   0 0x00000008 AddrDuplicate
       371708          0      1    0      0      0   0 0x00000008 AddrDuplicate
       145090          0      1    0      0      0   0 0x10001408 AddrDuplicate FullBlocksBad SubblocksBad IndblockBad
       145441          0      1    0      0      0   0 0x00000008 AddrDuplicate
...
        27094          0      1    1      0      0   0 0x10000000 IndblockBad
       439413          0      1    1      0      0   0 0x10000000 IndblockBad
...
         6950          0      1    0      0      0   0 0x00010000 DirEntryBad
         6955          0      1    0      0      0   0 0x00010000 DirEntryBad

You need run the offline fsck -y to fix above problems. 
Some files will be moved into lost+found directory after fsck -y, 
and fsck will punch a hole for the duplicated address, the application will hit input/output errors when access the hole. 
grep these iNum to ./inode.list

Following are the steps of the offline fsck:
1. Mount the file system in read only mode on a node, for example az18u3257
   # mmmount gpfsFS1 -o ro

2. Run tsfindinode to find out the corrupted files
   # tsfindinode -i ./inode.list /gpfsFS1

3. Backup the files found in step 2 to other place, for example, the local fs.

4. unmount the file system
   # mmumount gpfsFS1 -a
   # mmlsmount gpfsFS1 -L

4. Run mmfsck -y to fix the problem
   # mmfsck gpfsFS1 -v -y | tee mmfsck_gpfsFS1_y.out

5. If you have backup, recover the corrupted files from backup

6. Send the mmfsck_gpfsFS1_y.out to us for check
 
Please run above steps in the 'script' command. Thanks.
#######################

The file system is clean from the mmfsck -y output:
===================================================
               500736 inodes
               165114   allocated
                  164   repairable
                  164   repaired
                   16   damaged
                   11   deallocated
                  234   orphaned
                  234   attached
                    0   corrupt ACL references

            285696000 subblocks
             58004662   allocated
               185005   unreferenced
                    0   deletable
               191326   deallocated

              1898702 addresses
                    0   suspended

...
File system is clean.
===================================================

I think you can mount the file system of all the nodes and start your application. Thanks.





Looks like the log file is corrupt. Like you said, there are not fsstruct errors logged, but that is no guarantee that fs is not corrupt. You will need to run offline fsck to at least repair log files -

mmfsck <fs> -xk

- if ct has time to run full offline fsck, then that is preferable -

mmdsh -N all mmfsadm test fsck usePatchQueue 0
mmfsck <fs> -Vnm -xc -xsc --threads 128 -N <nsd server nodes> --patch-file <patch-file-name>  2>&1 | tee /tmp/fsckn.out

(--threads 128 to fasten the process)

=========================================================================

Hello,

An online mmfsck does not do everything that an offline mmfsck does.
I would recommend an offline mmfsck be run using a patchfile.  While
some FSSTRUCT errors indicate that file system metadata is corrupt,
users can avoid the downtime of running offline fsck to fix these
corruptions by looking closer at the FSSTRUCT errors.
If the errors are in a snapshot, then it is much easier to delete the
snapshot and its ancestors. Also some snapshot errors may not be fixable
by fsck. So deleting the snapshot would be the only options in such
cases.

Running fsck on selective nodes in the cluster:
This is done using the -N option of mmfsck command. The nodes specified
in this option only decide the fsck worker nodes. The stripe group
manager for the file system being scanned will always be the fsck master
node and it is selected implicitly. If users want to exclude the current
stripe group manager node from fsck run, then they have to first change
the stripe group manager node using mmchmgr and then run mmfsck.

Speeding up multi-pass fsck:
If there is insufficient memory to allow fsck to complete its scan in a
single pass, fsck would need multiple scan over the inodes. This can
significantly slow down fsck. To avoid this,  increase the pagepool size
(mmchconfig pagepool=<n>).

From your mmlsconfig output,  there are only 4 nodes that have a decent
amount of pagepool which is required to reduce the amount of time the
scan will take,  I would recommend limiting the mmfsck to just utilizing
these 4 nodes.

[io01-ib,io02-ib,io03-ib,io04-ib]
pagepool 32G
#  mmfsck /dev/work -v -n --patch-file /tmp/work.patchfile --threads 128
-N io01-ib,io02-ib,io03-ib,io04-ib  > mmfsck_n.out 2>&1
Once the mmfsck -n completes, upload /tmp/work.patchfile  and the
mmfsck_n.out file for review  then we can check it for problems and you
can run the mmfsck command to patch the filesystem using the patchfile
created by the mmfsck -n.
#  mmfsck /dev/work -v  --patch  --patch-file /tmp/work.patchfile
--threads 128  -N io01-ib,io02-ib,io03-ib,io04-ib  > mmfsck_patch.out
2>&1

You may want to check out multipathd before doing anything

Dec 26 21:21:54 gpfs01 multipathd: HOME_CAPA_01: sdah - tur checker
reports path is down
Dec 26 21:21:58 gpfs01 multipathd: HOME_CAPA_02: sdai - tur checker
reports path is down
Dec 26 21:21:58 gpfs01 multipathd: HOME_CAPA_02: sdds - tur checker
reports path is down
Dec 26 21:21:58 gpfs01 multipathd: HOME_CAPA_01: sddr - tur checker
reports path is down
Dec 26 21:21:59 gpfs01 multipathd: HOME_CAPA_01: sdah - tur checker
reports path is down
Dec 26 21:22:03 gpfs01 multipathd: HOME_CAPA_02: sdai - tur checker
reports path is down
Dec 26 21:22:03 gpfs01 multipathd: HOME_CAPA_02: sdds - tur checker
reports path is down
Dec 26 21:22:03 gpfs01 multipathd: HOME_CAPA_01: sddr - tur checker
reports path is down

$ grep multipathd io01-ib_*/var/log/messages | wc -l
188388
$ grep multipathd io02-ib_*/var/log/messages | wc -l
189761
$ grep multipathd io03-ib_*/var/log/messages | wc -l
188225
$ grep multipathd io04-ib_*/var/log/messages | wc -l
188524
$

[How to read mmfsck report]
=========identify corruption=============
Search of "Block allocation map of **"
example:
Block allocation map of SAS7K pool file inode 40 has one or more block corruptions.
Fix all block corruptions in the file? Yes
Block allocation map of SAS7K pool file has corrupt block 9523 record 19046 (reason 5).
Block allocation map of SAS7K pool file has corrupt block 9523 record 19046 (reason 7).
Block allocation map of SAS7K pool file has corrupt block 9523 record 19046 (reason 8).



